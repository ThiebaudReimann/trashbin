import asyncio
from google import genai
import numpy as np
import sounddevice as sd
from google.genai import types

def open_bin(bin: str) -> bool:
    """
    Ã–ffnet den passenden MÃ¼lleimer.
    Args:
        bin: ["bio", "rest", "papier", "gelb", "none"]
    """
    print(f"ðŸ”„ MÃ¼lleimer geÃ¶ffnet: {bin.upper()}")
    return True

# Google Gemini API Client
client = genai.Client(api_key="AIzaSyCrx8DF7Bh2moDSiNsOUxHJLY3QCyDlOWE", http_options={'api_version': 'v1alpha'})
model_id = "gemini-2.0-flash-exp"

config = {
    "response_modalities": ["AUDIO"],
    "system_instruction": types.Content(
        parts=[
            types.Part(
                text="Du bist ein smarter MÃ¼lleimer. Wenn ich dir ein Item nenne, sagst du mir, wo es hingehÃ¶rt "
                     "(RestmÃ¼ll, Papier, Gelb, Bio). Danach Ã¶ffnest du automatisch den passenden MÃ¼lleimer mit `open_bin`. "
                     "Antworte cool und lÃ¤ssig. Lehn unpassende Anfragen freundlich ab."
            )
        ]
    ),
    "tools": [open_bin],
    "speech_config": types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Kore")
        )
    ),
}

async def main():
    async with client.aio.live.connect(model=model_id, config=config) as session:
        while True:
            message = input("User> ")
            if message.lower() == "exit":
                break
            await session.send(input=message, end_of_turn=True)

            # Roh-Stream fÃ¼r Audio-Wiedergabe Ã¶ffnen
            stream = sd.RawOutputStream(samplerate=24000, channels=1, dtype='int16', blocksize=1024)
            stream.start()

            async for response in session.receive():
                print("Checkpoint 1")
                # ðŸ”¹ Falls keine gÃ¼ltige Antwort vorhanden ist, Ã¼berspringen
                if not response.server_content or not response.server_content.model_turn:
                    print("âš  Fehler: Keine gÃ¼ltigen Audiodaten erhalten.")
                    continue

                print("Checkpoint 2")
                parts = response.server_content.model_turn.parts
                if not parts or not parts[0].inline_data:
                    print("âš  Fehler: Keine Inline-Audio-Daten vorhanden.")
                    continue

                print("Checkpoint 3")
                if response.tool_call:
                    print("Tool Call")
                    for function_call in response.tool_call.function_calls:
                        print(f"ðŸ”§ Tool-Funktion: {function_call.name}")
                        if function_call.name == "open_bin":
                            print("ðŸ”„ MÃ¼lleimer Ã¶ffnen")
                            bin_type = function_call.args.get("bin", "none")
                            open_bin(bin_type)
                    continue  # Schleife weiterfÃ¼hren, damit Audio nicht blockiert wird


                print("Checkpoint 4")
                # ðŸ”¹ PCM-Daten fÃ¼r die Audioausgabe verarbeiten
                if parts[0].inline_data.data:
                    pcm_data = parts[0].inline_data.data
                    audio_array = np.frombuffer(pcm_data, dtype=np.int16)

                    # In BlÃ¶cken schreiben, falls nÃ¶tig
                    chunk_size = 1024
                    for i in range(0, len(audio_array), chunk_size):
                        stream.write(audio_array[i:i+chunk_size].tobytes())



            print("ðŸ”´ GesprÃ¤ch beendet.")
            stream.stop()
            stream.close()

if __name__ == "__main__":
    asyncio.run(main())
